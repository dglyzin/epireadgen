{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as tdist\n",
    "import torch.nn.functional as F \n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model\n",
    "helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alleles = ['A', 'C', 'G', 'T', '_']\n",
    "\n",
    "def to_allele(idxs):\n",
    "    return([alleles[int(idx)] for idx in idxs])\n",
    "\n",
    "def from_allele(name):\n",
    "    return(float(alleles.index(name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_seq(size, p_init_seq=torch.tensor([1/4, 1/4, 1/4, 1/4])):\n",
    "    return(tdist.Categorical(\n",
    "        p_init_seq.expand(size, -1)).sample())\n",
    "\n",
    "def init_trans_seq(size, p_init_trans_seq=1/2):\n",
    "    return(tdist.Bernoulli(\n",
    "        p_init_trans_seq * torch.ones(size)).sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edit_time(seq_size, t, alpha1):\n",
    "    '''\n",
    "    dependence on site index in seq:\n",
    "    time scale at each site with Gamma distribution\n",
    "    (Yang [1993])\n",
    "    \n",
    "    Inputs:\n",
    "     - ``t`` and ``alpha1`` -- describe time and variance\n",
    "     ex:  t: 0.01, alpha1: 0.1\n",
    "    \n",
    "    '''\n",
    "    gd = tdist.Gamma(torch.arange(1, seq_size+1).float(),\n",
    "                     alpha1*torch.ones(seq_size))\n",
    "\n",
    "    rr = gd.sample()\n",
    "    # print(\"gamma rr = \", rr)\n",
    "    # print(\"t original = \", t)\n",
    "    ts = rr*t/gd.mean\n",
    "    # print(\"ts = \", ts)\n",
    "    return(ts)\n",
    "\n",
    "\n",
    "def high_level(seq_size, ltrans_seq, probs):\n",
    "    \n",
    "    '''Dependence from previus seq, not from seq shift!\n",
    "    So p(M|M) means P(seq_{i}=M|last_seq_{i}=M)\n",
    "    \n",
    "    Inputs:\n",
    "    - ``ltrans_seq`` -- last transition seq\n",
    "    - ``probs`` -- dict with keys \"M|M\", \"M|D\"\n",
    "    ex: {\"M|M\":0.9, \"M|D\": 0.7}\n",
    "    '''\n",
    "    \n",
    "    trans_seq = ltrans_seq.detach().clone()\n",
    "    # 1 means M:\n",
    "    cond_M = ltrans_seq == 1\n",
    "    \n",
    "    # TODO: dependence on previus state\n",
    "    # <M, D>|M:\n",
    "    trans_seq[cond_M] = tdist.Bernoulli(\n",
    "        probs[\"M|M\"]*torch.ones(seq_size)[cond_M]).sample()\n",
    "    \n",
    "    # <M, D>|D\n",
    "    trans_seq[torch.logical_not(cond_M)] = tdist.Bernoulli(\n",
    "        probs[\"M|D\"]*torch.ones(seq_size)[torch.logical_not(cond_M)]).sample()\n",
    "    \n",
    "    return(trans_seq)\n",
    "\n",
    "\n",
    "def low_level(lseq, trans_seq, alpha, ts, prob_del, Dn):\n",
    "    '''\n",
    "    Compute emissions for M and D states (from `trans_seq`):\n",
    "        P(<A, C, G, T>_{i}|<A, C, G, T>_{i-1} , M) or P(\"_\"|D)\n",
    "    if M state given use time scale Yang [1993]\n",
    "        ts\n",
    "    and Jukes-Cantor substitution matrix:\n",
    "        S = torch.tensor([[rt, st, st, st],\n",
    "                          [st, rt, st, st],\n",
    "                          [st, st, rt, st],\n",
    "                          [st, st, st, rt]])\n",
    "    if D state given set binomial(Dn, prob_del) for\n",
    "    each D_{i} to generate subsequence of \"_\" in each i\n",
    "    (`i` taken from `trans_seq`)\n",
    "    \n",
    "    Inputs:\n",
    "    - ``prob_del`` and ``Dn`` used for subsequence of \"_\":\n",
    "    binomial(Dn, prob_del)\n",
    "    ex: prob_del: 0.1, Dn: 3\n",
    "    \n",
    "    - ``alpha`` and ``ts`` used for `rt` and `ts` parameters\n",
    "    of `S` matrix.\n",
    "    \n",
    "    '''\n",
    "    rt = torch.unsqueeze(1/4*(1+3*np.exp(-4*alpha*ts)), 0)\n",
    "    st = torch.unsqueeze(1/4*(1-np.exp(-4*alpha*ts)), 0)\n",
    "    # print(\"rt, st = \", (rt, st))\n",
    "\n",
    "    \n",
    "    # FOR M:\n",
    "    cond_trans_M = trans_seq==1\n",
    "    # print(\"cond_trans_M:\")\n",
    "    # print(cond_trans_M)\n",
    "    cond_A = lseq == from_allele(\"A\")\n",
    "    probs_A = [rt, st, st, st]\n",
    "    \n",
    "    cond_C = lseq == from_allele(\"C\")\n",
    "    probs_C = [st, rt, st, st]\n",
    "    \n",
    "    cond_G = lseq == from_allele(\"G\")\n",
    "    probs_G = [st, st, rt, st]\n",
    "    \n",
    "    cond_T = lseq == from_allele(\"T\")\n",
    "    probs_T = [st, st, st, rt]\n",
    "    \n",
    "    cond_del = lseq == from_allele(\"_\")\n",
    "    probs_del = [1/4 * torch.unsqueeze(torch.ones(seq_size), 0), \n",
    "                 1/4 * torch.unsqueeze(torch.ones(seq_size), 0),\n",
    "                 1/4 * torch.unsqueeze(torch.ones(seq_size), 0),\n",
    "                 1/4 * torch.unsqueeze(torch.ones(seq_size), 0)]\n",
    "    \n",
    "    seq = lseq.detach().clone()\n",
    "    \n",
    "    emissions = [(cond_A, probs_A), (cond_C, probs_C),\n",
    "                 (cond_G, probs_G), (cond_T, probs_G),\n",
    "                 (cond_T, probs_T), (cond_del, probs_del)\n",
    "                ]\n",
    "    for cond_word, probs_word in emissions:\n",
    "        cond_M_A = torch.logical_and(cond_trans_M, cond_word)\n",
    "        size_M_A = len(lseq[cond_M_A])\n",
    "        seq[cond_M_A] = tdist.Categorical(\n",
    "            torch.cat(probs_word).T[cond_M_A]).sample()  # .expand(size_M_A, -1))\n",
    "    # print(\"seq after M:\")\n",
    "    # print(seq)\n",
    "    # END FOR\n",
    "    \n",
    "    # FOR D:\n",
    "    cond_trans_D = trans_seq==0\n",
    "    # print(\"cond_trans_D:\")\n",
    "    # print(cond_trans_D)\n",
    "    idxs = (cond_trans_D).nonzero().flatten()\n",
    "    # print(\"idxs:\")\n",
    "    # print(idxs)\n",
    "    idxs_shift_sample = tdist.Binomial(Dn, prob_del * torch.ones(idxs.size()[0])).sample()\n",
    "    # print(\"idxs_shift_sample:\")\n",
    "    # print(idxs_shift_sample)\n",
    "    \n",
    "    # add subsequences idxs to del:\n",
    "    idxs1 = torch.cat((idxs, idxs+idxs_shift_sample),0).long()\n",
    "    # print(\"idxs1:\")\n",
    "    # print(idxs1)\n",
    "    \n",
    "    # cut oversize, del subsequnces:\n",
    "    seq[idxs1[idxs1<seq.size()[0]]] = from_allele(\"_\")\n",
    "    \n",
    "    # print(\"seq after D:\")\n",
    "    # print(seq)\n",
    "    # END FOR\n",
    "      \n",
    "    # cd = tdist.Categorical(S)\n",
    "    # dwords = tdist.Categorical(S)\n",
    "    return(seq)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init seq:\n",
      "CATGCACCACCGGCCTTGGGGGGTAGACACATACCCAACGAGAGTTTCACCTACGCGTGGACATGTCTGGTATGACTAGGGAATGCTGGGCGGTGCGACT\n",
      "\n",
      "seq:\n",
      "C__GCA__CCC_GCC_TGGCGGATAGA_AC_CAGACAAC_A__GTTTCACCTAC__GT__C__GG__TGCG__GATTCA_GAGTG_TG____GTGGGTCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valdecar/anaconda3/envs/math/lib/python3.6/site-packages/ipykernel/__main__.py:120: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
     ]
    }
   ],
   "source": [
    "# init:\n",
    "seq_size = 100\n",
    "ilseq = init_seq(seq_size)\n",
    "iltseq = init_trans_seq(seq_size)\n",
    "print(\"init seq:\")\n",
    "print(\"\".join(to_allele(ilseq)))\n",
    "\n",
    "# main\n",
    "# transition:\n",
    "ltseq = high_level(seq_size, iltseq, {\"M|M\":0.9, \"M|D\": 0.7})\n",
    "# print(\"last transition seq:\")\n",
    "# print(ltseq)\n",
    "\n",
    "# time scale Yang [1993]:\n",
    "ts = edit_time(seq_size, 0.01, 0.1)\n",
    "# print(\"ts:\")\n",
    "# print(ts)\n",
    "\n",
    "# emission:\n",
    "seq = low_level(ilseq, ltseq, 10.0, ts, 0.1, 3)\n",
    "print(\"\\nseq:\")\n",
    "print(\"\".join(to_allele(seq)))\n",
    "# trans_seq = \n",
    "# low_level(lseq, trans_seq, alpha, ts, 0.9)\n",
    "# ltseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iteration(lseq, ltseq, t=0.01, time_alpha=0.1, s_alpha=10.0):\n",
    "    '''\n",
    "    s_alpha = 10.0  # for transition matrix S\n",
    "    time_alpha = 0.9  # for gamma dist\n",
    "    t = 0.01  # timestep \\in [0, 1]\n",
    "    '''\n",
    "    seq_size = lseq.size()[0]\n",
    "    \n",
    "    # transition:\n",
    "    ltseq = high_level(seq_size, iltseq, {\"M|M\":0.9, \"M|D\": 0.7})\n",
    "    # print(\"last transition seq:\")\n",
    "    # print(ltseq)\n",
    "\n",
    "    # time scale Yang [1993]:\n",
    "    ts = edit_time(seq_size, t, time_alpha)\n",
    "    # print(\"ts:\")\n",
    "    # print(ts)\n",
    "\n",
    "    # emission:\n",
    "    seq = low_level(ilseq, ltseq, s_alpha, ts, 0.1, 3)\n",
    "    # print(\"seq:\")\n",
    "    # print(\"\".join(to_allele(seq)))\n",
    "    return(seq, ltseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init seq:\n",
      "GGGTCCAAAAGCGGGGGAATTCCTATGGGTAAGATAGGCGCACGCTTCAGCGTCTCCGTAGAAGCCGCAGCGTTAAGGAGAATAACATAAAGTTCTTCTC\n",
      "\n",
      "seq:\n",
      "GAGGGC__AAGACAGGGAATCCCT_TGGGA__TAT__GTG_ATC__TCAGCG____T_TCG__A__GCAG_GTG_A_GAG_TTAA_ATC_AG_GCTT_TT\n"
     ]
    }
   ],
   "source": [
    "# init:\n",
    "seq_size = 100\n",
    "ilseq = init_seq(seq_size)\n",
    "iltseq = init_trans_seq(seq_size)\n",
    "print(\"init seq:\")\n",
    "print(\"\".join(to_allele(ilseq)))\n",
    "seq, tseq = ilseq, iltseq\n",
    "\n",
    "for i in range(30):\n",
    "    seq, tseq = iteration(seq, tseq)\n",
    "print(\"\\nseq:\")\n",
    "print(\"\".join(to_allele(seq)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loop for a tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer_succ(t):\n",
    "    time_dist = tdist.Uniform(0, 0.1)\n",
    "    t += float(time_dist.sample())\n",
    "    return(t)\n",
    "    \n",
    "def loop(N, timer, net=None, nodes=[]):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # init:\n",
    "    if net is None:\n",
    "        lseq = init_seq(seq_size,\n",
    "                        p_init_seq=torch.tensor([1/4, 1/4, 1/4, 1/4]))\n",
    "        ltseq = init_trans_seq(seq_size, p_init_trans_seq=1/2)\n",
    "        net = nx.DiGraph()\n",
    "        t = timer(0)\n",
    "        \n",
    "        net.add_node(\"s\", seq=\"\".join(to_allele(lseq)),\n",
    "                     pos=(1, 1))\n",
    "        nodes = [(\"s\", lseq, ltseq, t)]\n",
    "        return(loop(N-1, timer, net, nodes))\n",
    "    \n",
    "    # finish:\n",
    "    if N <= 0:\n",
    "        return(net)\n",
    "    \n",
    "    # main:\n",
    "    # choice that with minimum time:\n",
    "    nodes.sort(key=lambda x: x[-1])\n",
    "    first = nodes.pop(0)\n",
    "    pidx, lseq, ltseq, t = first\n",
    "    lidx = pidx + \"0\"\n",
    "    ridx = pidx + \"1\"\n",
    "    p_pos = net.nodes[pidx]['pos']\n",
    "    \n",
    "    left_seq, left_tseq = iteration(lseq, ltseq)\n",
    "    right_seq, right_tseq = iteration(lseq, ltseq)\n",
    "    lt = timer(t)\n",
    "    \n",
    "    net.add_node(lidx, seq=\"\".join(to_allele(left_seq)),\n",
    "                 pos=(p_pos[0]+0.01*lt, p_pos[1]+lt*30+30/N))\n",
    "    net.add_edge(pidx, lidx, time=lt)\n",
    "    rt = timer(t)\n",
    "    net.add_node(ridx, seq=\"\".join(to_allele(right_seq)),\n",
    "                pos=(p_pos[0]-0.01*rt, p_pos[1]+rt*30+30/N))\n",
    "    net.add_edge(pidx, ridx, time=rt)\n",
    "    nodes.append((lidx, left_seq, left_tseq, lt))\n",
    "    nodes.append((ridx, right_seq, right_tseq, rt))\n",
    "    return(loop(N-1, timer, net, nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = loop(10, timer_succ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({'s': (1, 1), 's0': (1.0008799329586326, 6.973132209231457), 's1': (0.9985589176416397, 8.656580408414206), 's00': (1.002474001608789, 15.505338159700235), 's01': (0.9994487079232931, 15.016807315250238), 's010': (1.0012430205754936, 24.685459557565906), 's011': (0.9971755396388471, 26.122026454302528), 's10': (1.0009172266721726, 20.731507500012718), 's11': (0.9963853763788939, 20.17720419665178), 's000': (1.004350966066122, 27.1362315316995), 's001': (1.0005370890535414, 27.316075825442873), 's0100': (1.0033903862163425, 38.62755648011253), 's0101': (0.9984582717716695, 40.539705969038465), 's0000': (1.0070593437179922, 45.26136448731025), 's0001': (1.0016993990913035, 45.09093245615562), 's0010': (1.0034183793142437, 50.95994660754999), 's0011': (0.9979447156190873, 50.09319612880548), 's01000': (1.0059723158739506, 76.37334545293734), 's01001': (1.0009087496064604, 76.07246630975888)}, data='pos')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(nx.dfs_edges(net, \"0\"))\n",
    "net.nodes(data=\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "pos =  net.nodes(data=\"pos\")\n",
    "#\n",
    "labels=nx.draw_networkx_labels(net, pos=pos)\n",
    "# labels=nx.draw_networkx_labels(net,pos=nx.spring_layout(net))\n",
    "edge_labels = dict([((u, v), \"%.2f\" % (float(c)))\n",
    "                    for u, v, c in net.edges(data=\"time\")])\n",
    "edge_labels=nx.draw_networkx_edge_labels(net, pos=pos,\n",
    "                                         edge_labels=edge_labels)\n",
    "# nx.draw(net, pos=nx.spring_layout(net))\n",
    "\n",
    "nx.draw(net, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Gamma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 5., 11.,  6., 12., 11., 16., 20.,  6.,  8.,  5.]),\n",
       " array([ 84.7612  ,  89.795235,  94.82926 ,  99.8633  , 104.89732 ,\n",
       "        109.93136 , 114.96539 , 119.99942 , 125.033455, 130.06749 ,\n",
       "        135.10152 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha1 = 0.9  # for gamma dist\n",
    "t = 1  # timestep\n",
    "r = float(100)  # site number in seq\n",
    "gd = tdist.Gamma(torch.tensor(r),torch.tensor(alpha1))\n",
    "def gen(t):\n",
    "    rr = gd.sample()\n",
    "    return(rr)\n",
    "    # return(rr*t/gd.mean)\n",
    "\n",
    "# print(\"gamma rr = \", rr)\n",
    "# print(\"t original = \", t)\n",
    "# print(\"t = \", t)\n",
    "data = [gen(t) for i in range(100)]\n",
    "\n",
    "%matplotlib\n",
    "plt.hist(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gamma distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 1000\n",
      "tensor(7.7778)\n",
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 30.,  50., 102., 133., 150., 132., 113.,  87.,  57.,  80.,  33.,\n",
       "         12.,   7.,   9.,   3.,   0.,   0.,   1.,   1.]),\n",
       " array([ 1.        ,  2.10526316,  3.21052632,  4.31578947,  5.42105263,\n",
       "         6.52631579,  7.63157895,  8.73684211,  9.84210526, 10.94736842,\n",
       "        12.05263158, 13.15789474, 14.26315789, 15.36842105, 16.47368421,\n",
       "        17.57894737, 18.68421053, 19.78947368, 20.89473684, 22.        ]),\n",
       " <a list of 19 Patch objects>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = tdist.Gamma(torch.tensor(7.0),torch.tensor(0.9))\n",
    "data = [int(dd.sample()) for i in range(1000)]\n",
    "print(len(set(data)), len(data))\n",
    "classes = set(data)\n",
    "# print(classes)\n",
    "print(dd.mean)\n",
    "%matplotlib\n",
    "# plt.figure(figsize=(10,1))\n",
    "plt.hist(data, len(classes), # density=True, \n",
    "        # orientation='horizontal',\n",
    "        stacked=True,\n",
    "        rwidth=0.1, label = [str(c) for c in classes])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Wright-Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model0(init_i, n=0, states=torch.tensor([])):\n",
    "    Ns = torch.sum(init_i, -1).int()\n",
    "    # Ns = N * torch.ones(len(init_i.shape))\n",
    "    '''\n",
    "    if not all(torch.sum(init_i, -1).int() == Ns.int()):\n",
    "        print(init_i)\n",
    "        print(torch.sum(init_i, -1))\n",
    "        print(Ns)\n",
    "        print(torch.sum(init_i, -1) == Ns)\n",
    "        raise(BaseException(\"wrong args\"))\n",
    "    '''\n",
    "    if n <= 0:\n",
    "        return(states)\n",
    "    n -= 1\n",
    "    i = torch.tensor(init_i).float()\n",
    "    # print((i.T/Ns).T)\n",
    "    # print(Ns.unsqueeze(1))\n",
    "    dd = tdist.Binomial(Ns.unsqueeze(1), (i.T/Ns).T)\n",
    "    x = (Ns * F.normalize(dd.sample(), p=1, dim=-1).T).T\n",
    "    \n",
    "    # print(\"x = \", x)\n",
    "    # print(\"prob(x_t|x_t-1)= \", torch.exp(dd.log_prob(x)))\n",
    "    return(model0(x, n=n,\n",
    "                  states=torch.cat((states, torch.unsqueeze(x, 0)), 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Wright-Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valdecar/anaconda3/envs/math/lib/python3.6/site-packages/ipykernel/__main__.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# states = model0(torch.tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "#                               [1, 1, 1, 1, 1, 1, 1, 3, 0]]), 10, 70)\n",
    "states = model0(torch.tensor([[50000, 50000] for i in range(100)]), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 100, 2])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# states[:,0,:].T\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (states[0].T/torch.sum(states[0], -1).int()).T\n",
    "# (states[:,i,:].T/torch.sum(states[:,i,:],-1).int())[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Wright-Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.ylim(0, 1)\n",
    "allele = 0\n",
    "for i in range(states.shape[-2]):\n",
    "    plt.plot((states[:,i,:].T/torch.sum(states[:,i,:],-1).int())[allele])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.ylim(0, 100000)\n",
    "allele = 0\n",
    "for i in range(states.shape[-2]):\n",
    "    plt.plot(states[:,i,:].T[allele])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "gen=0\n",
    "for i in range(states.shape[-1]):\n",
    "    plt.plot(states[:,gen,:].T[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model SEIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model1(T=3, dt=0.01, S0=997, E0=0, I0=3, R0=0,\n",
    "           beta=1.5, eps=0.35, gamma=0.035, mu=0.005,\n",
    "           states=torch.tensor([])):\n",
    "    '''Assuming birth=death'''\n",
    "    if T==0:\n",
    "        return(states)\n",
    "        # return(S0, E0, I0, R0, states)\n",
    "    \n",
    "    N = S0+E0+I0+R0\n",
    "    S = dt*(mu*N-mu*S0-beta*I0*S0/N)+S0\n",
    "    E = dt*(beta*S0*I0/N-(eps+mu)*E0)+E0\n",
    "    I = dt*(eps*E0-(gamma+mu)*I0)+I0\n",
    "    R = dt*(gamma*I0 - mu*R0)+R0\n",
    "    T-=1\n",
    "    # print(\"N=\",S+E+I+R)\n",
    "    # print(S, E, I, R)\n",
    "    return(model1(T, dt=dt, S0=S, E0=E, I0=I, R0=R,\n",
    "                  beta=beta, eps=eps, gamma=gamma, mu=mu,\n",
    "                 states=torch.cat((states,\n",
    "                                   torch.unsqueeze(torch.tensor([S, E, I, R]), 0)), 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test SEIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7001, 4])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for deep recursion avoidance:\n",
    "states = torch.tensor([[997, 0, 3, 0]])\n",
    "for i in range(7):\n",
    "    res = model1(1000, S0=float(states[-1][0]), E0=float(states[-1][1]),\n",
    "                 I0=float(states[-1][2]), R0=float(states[-1][3]))\n",
    "    states = torch.cat((states, res),0)\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results SEIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe44fcad4e0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.ylim(0, 1000)\n",
    "\n",
    "for i in range(states.shape[-1]):\n",
    "    plt.plot(states.T[i], label=['S', 'E', 'I', 'R'][i])\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "# for vectorized, sampled, depended:\n",
    "def model1(init_i, N):\n",
    "    # mu = torch.tensor(0.5)\n",
    "    # sigma = torch.tensor(0.1)\n",
    "    # p = pyro.sample(\"latent_fairness\", dist.Normal(mu, sigma))\n",
    "    # print(\"p = \", p)\n",
    "    i = init_i\n",
    "    \n",
    "    # vectorized, sampled, dependent:\n",
    "    p = i/N\n",
    "    # dd = dist.Bernoulli(p).expand([7, 2]).to_event(1)\n",
    "    x = dd.sample()\n",
    "    print(\"x= \", x)\n",
    "    print(\"prob(x)= \", torch.exp(dd.log_prob(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=  tensor([[0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "prob(x)=  tensor([0.3265, 0.2449, 0.2449, 0.2449, 0.3265, 0.3265, 0.3265])\n"
     ]
    }
   ],
   "source": [
    "model1(3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "# for vectorized, sampled, depended:\n",
    "def model(init_i, N):\n",
    "    # mu = torch.tensor(0.5)\n",
    "    # sigma = torch.tensor(0.1)\n",
    "    # p = pyro.sample(\"latent_fairness\", dist.Normal(mu, sigma))\n",
    "    # print(\"p = \", p)\n",
    "    i = init_i\n",
    "    \n",
    "    # vectorized, sampled, dependent:\n",
    "    with pyro.plate(\"data_loop\", size=3, subsample_size=2) as ind:\n",
    "        p = i/N\n",
    "        dd = dist.Bernoulli(p).expand([7, 2]).to_event(1)\n",
    "        print(\"dd.batch_shape:\")\n",
    "        print(dd.batch_shape)\n",
    "        print(\"dd.event_shape:\")\n",
    "        print(dd.event_shape)\n",
    "        x = dd.sample()\n",
    "        print(\"x = \", x)\n",
    "        print(\"prob(x) = \", torch.exp(dd.log_prob(x)))\n",
    "        # print(\"accurate: \",\n",
    "        #       torch.tensor([(p if x0 else 1-p)*(p if x1 else 1-p)\n",
    "        #                     for x0, x1 in x]))\n",
    "\n",
    "        y = pyro.sample(\"y\", dd)\n",
    "        print(\"y = \", y)\n",
    "        print(\"ind:\")\n",
    "        print(ind)\n",
    "        \n",
    "        # a = pyro.sample(\"obs\", dd, obs=data.index_select(0, ind))\n",
    "        # print(\"a:\")\n",
    "        # print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd.batch_shape:\n",
      "torch.Size([7])\n",
      "dd.event_shape:\n",
      "torch.Size([2])\n",
      "x =  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "prob(x) =  tensor([0.2449, 0.2449, 0.3265, 0.2449, 0.2449, 0.2449, 0.2449])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch inside plate('data_loop') at site y dim -1, 2 vs 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bd91096b60aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-1f8447b8ea68>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(init_i, N)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#                     for x0, x1 in x]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ind:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/math/lib/python3.6/site-packages/pyro/primitives.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(name, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_observed\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# apply the stack and return its return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mapply_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/math/lib/python3.6/site-packages/pyro/poutine/runtime.py\u001b[0m in \u001b[0;36mapply_stack\u001b[0;34m(initial_msg)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpointer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/math/lib/python3.6/site-packages/pyro/poutine/plate_messenger.py\u001b[0m in \u001b[0;36m_process_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBroadcastMessenger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pyro_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/math/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/math/lib/python3.6/site-packages/pyro/poutine/broadcast_messenger.py\u001b[0m in \u001b[0;36m_pyro_sample\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtarget_batch_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtarget_batch_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     raise ValueError(\"Shape mismatch inside plate('{}') at site {} dim {}, {} vs {}\".format(\n\u001b[0;32m---> 59\u001b[0;31m                         f.name, msg['name'], f.dim, f.size, target_batch_shape[f.dim]))\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mtarget_batch_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# Starting from the right, if expected size is None at an index,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch inside plate('data_loop') at site y dim -1, 2 vs 7"
     ]
    }
   ],
   "source": [
    "model(3,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([-0.5929,  0.3222,  0.2136])\n",
      "y:  tensor([[0.8491],\n",
      "        [1.8800]])\n"
     ]
    }
   ],
   "source": [
    "x_axis = pyro.plate(\"x\", 3, dim=-1)\n",
    "y_axis = pyro.plate(\"y\", 2, dim=-2)\n",
    "with x_axis:\n",
    "    x = pyro.sample(\"x\", dist.Normal(0, 1))\n",
    "    # this dont work here because of plate:\n",
    "    # x = pyro.sample(\"x\", dist.Normal(0, 1).expand([5, 2]).to_event(1))\n",
    "with y_axis:\n",
    "    y = pyro.sample(\"y\", dist.Normal(0, 1))\n",
    "print(\"x: \", x)\n",
    "print(\"y: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:math]",
   "language": "python",
   "name": "conda-env-math-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
